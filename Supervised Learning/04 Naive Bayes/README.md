## Intro

Naive Bayes is a supervised machine learning algorithm that can be trained to classify data into multi-class categories. In the heart of Naive Bayes algorithm is the probabilistic model that computes the conditional probabilities of the input features and assigns the probability distributions to each of possible classes.

In this lesson, we will review the conditional probability and Bayes Rule. Next, we will learn how Naive Bayes algorithm works. At the end of the lesson, you will do a coding exercise to apply Naive Bayes in one of the Natural Language Processing (NLP) tasks, ie. spam emails classification, using Scikit-Learn library.


## Outro
Congratulations! That was the end of the Naive Bayes section. You now know how to implement Naive Bayes and use it to make predictions in real data, such as detecting spam emails.

To recap, you learn how Naive Bayes algorithm applies probabilistic computation in a classification task. This algorithm falls under the Supervised Machine Learning algorithm, where we can train a set of data and label them according to their categories.

In the next lesson, we will learn how to build Bayes Nets. If the output of the Naive Bayes algorithm is a classification, the output for the Bayes Net is a probability distribution. Furthermore, while the Naive Bayes assumes conditional independence, the more general Bayes Nets specify the attributes in probability distributions and conditional independence.

See you in the next section!
