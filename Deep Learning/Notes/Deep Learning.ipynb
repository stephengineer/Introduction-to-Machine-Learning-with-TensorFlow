{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd884ce9",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "## Github Repos\n",
    "\n",
    "- [Deep Learning](https://github.com/udacity/deep-learning)\n",
    "- [Deep Learning with Pytorch](https://github.com/udacity/deep-learning-v2-pytorch)\n",
    "\n",
    "## Content\n",
    "\n",
    "1. [Introductioin to Neural Networks](#Introductioin-to-Neural-Networks)\n",
    "2. [Implementing Gradient Descent](#Implementing-Gradient-Descent)\n",
    "3. [Training Neural Network](#Training-Neural-Network)\n",
    "4. [Deep Learning with TensorFlow](#Deep-Learning-with-TensorFlow)\n",
    "5. [Deep Learning with PyTorch](#Deep-Learning-with-PyTorch)\n",
    "6. [Convolutional Neural Networks](#Convolutional-Neural-Networks)\n",
    "7. [Recurrent Neural Networks](#Recurrent-Neural-Networks)\n",
    "8. [Generative Adversarial Networks](#Generative-Adversarial-Networks)\n",
    "9. [Deploying a Model](#Deploying-a-Model)\n",
    "10. [Projects](#Projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60da5e67",
   "metadata": {},
   "source": [
    "## Introductioin to Neural Networks\n",
    "\n",
    "### Gradient Descent\n",
    "[Principles and the math behind the gradient descent algorithm](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/Introduction%20to%20Neural%20Networks/Gradient%20Descent.pdf)\n",
    "\n",
    "#### Error Function\n",
    "\n",
    "- The error function should be differentiable\n",
    "- THe error function should be continuous\n",
    "\n",
    "### Activation Function\n",
    "\n",
    "#### Gradient Descent Algorithm\n",
    "\n",
    "- Sigmoid activation function\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "- Derivative of the sigmoid function\n",
    "$$\\sigma'(x)=\\sigma(x)(1-\\sigma(x))$$\n",
    "\n",
    "- Output (prediction) formula\n",
    "\n",
    "$$\\hat{y} = \\sigma(w_1 x_1 + w_2 x_2 + b)$$\n",
    "\n",
    "- Error function\n",
    "\n",
    "$$Error(y, \\hat{y}) = - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})$$\n",
    "\n",
    "- The function that updates the weights\n",
    "\n",
    "$$ w_i \\longrightarrow w_i + \\alpha (y - \\hat{y}) x_i$$\n",
    "\n",
    "$$ b \\longrightarrow b + \\alpha (y - \\hat{y})$$\n",
    "\n",
    "\n",
    "```python\n",
    "# Activation (sigmoid) function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def output_formula(features, weights, bias):\n",
    "    return sigmoid(np.dot(features, weights) + bias)\n",
    "\n",
    "def error_formula(y, output):\n",
    "    return - y*np.log(output) - (1 - y) * np.log(1-output)\n",
    "\n",
    "def update_weights(x, y, weights, bias, learnrate):\n",
    "    output = output_formula(x, weights, bias)\n",
    "    d_error = y - output\n",
    "    weights += learnrate * d_error * x\n",
    "    bias += learnrate * d_error\n",
    "    return weights, bias\n",
    "```\n",
    "\n",
    "### One-hot Encoding\n",
    "Use the `get_dummies` function in Pandas in order to one-hot encode the data.\n",
    "\n",
    "```python\n",
    "# Make dummy variables for rank\n",
    "one_hot_data = pd.concat([data, pd.get_dummies(data['rank'], prefix='rank')], axis=1)\n",
    "```\n",
    "\n",
    "### Maximum Likelihood\n",
    "- log(ab) = log(a) + log(b)\n",
    "\n",
    "### Cross Entropy\n",
    "A higher cross-entropy implies a lower probability for an event. (cross-entropy is inversely proportional to the total probability of an outcome.)\n",
    "\n",
    "- A good model gives a low cross entropy\n",
    "- A bad model gives a high cross entropy\n",
    "\n",
    "$$\n",
    "CE = - \\sum_{i=1}^m y_i ln(p_i) + (1-y_i) ln (1-p_i)\n",
    "$$\n",
    "\n",
    "#### Coding Cross-entropy\n",
    "```python\n",
    "# Y is for the category, and P is the probability.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cross_entropy(Y, P):\n",
    "    Y = np.float_(Y)\n",
    "    P = np.float_(P)\n",
    "    return -np.sum(Y * np.log(P) + (1 - Y) * np.log(1 - P))\n",
    "```\n",
    "\n",
    "### Logistic Regression\n",
    "1. Start with random weights: $w_1, ... , w_n, b$\n",
    "2. For every point $(x_1, ... , x_n)$: update $w_i, b$\n",
    "3. Reapeat until error is small\n",
    "\n",
    "### Neural Network Architecture\n",
    "- Input Layer\n",
    "- Hidden Layer\n",
    "- Output Layer\n",
    "\n",
    "### Feedforward\n",
    "\n",
    "### Backpropagation\n",
    "- Doing a feedforward operation.\n",
    "- Comparing the output of the model with the desired output.\n",
    "- Calculating the error.\n",
    "- Running the feedforward operation backwards (backpropagation) to spread the error to each of the weights.\n",
    "- Use this to update the weights, and get a better model.\n",
    "- Continue this until we have a model that is good.\n",
    "\n",
    "#### Backpropagate the error\n",
    "$$ (y-\\hat{y}) \\sigma'(x) $$\n",
    "\n",
    "```python\n",
    "def error_term_formula(x, y, output):\n",
    "    return (y - output)*sigmoid_prime(x)\n",
    "```\n",
    "\n",
    "[Lab: Analyzing Student Data](../../notebooks/01%20Introduction%20to%20Neural%20Networks/StudentAdmissions.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74087f",
   "metadata": {},
   "source": [
    "## Implementing Gradient Descent\n",
    "\n",
    "### Mean Squared Error Function\n",
    "$$\n",
    "E=\\frac{1}{2m}\\sum_{\\mu}(y^{\\mu}-\\hat{y}^{\\mu})^2\n",
    "$$\n",
    "\n",
    "- [Gradient Descent](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Gradient%20Descent.pdf)\n",
    "- [Gradient Descent Code](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Gradient%20Descent%20Code.pdf)\n",
    "- [Gradient Descent Implementing](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Gradient%20Descent%20Implementing.pdf)\n",
    "- [Multilayer Perceptrons](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Multilayer%20Perceptrons.pdf)\n",
    "- [Backpropagation](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Backpropagation.pdf)\n",
    "- [Backpropagation Implementing](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Backpropagation%20Implementing.pdf)\n",
    "\n",
    "Further reading\n",
    "- From Andrej Karpathy: [Yes, you should understand backprop](https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b#.vt3ax2kg9)\n",
    "- Also from Andrej Karpathy, [a lecture from Stanford's CS231n course](https://www.youtube.com/watch?v=59Hbtz7XgjM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6672e0",
   "metadata": {},
   "source": [
    "## Training Neural Network\n",
    "\n",
    "### Overfitting and Underfitting\n",
    "\n",
    "- Overfitting -> high variance\n",
    "- Underfitting -> high bias\n",
    "\n",
    "![earlyStopping](./img/earlyStopping.png)\n",
    "\n",
    "### Regularization\n",
    "Large coefficients -> overfitting\n",
    "- L1 Error Function: Good for feature selection\n",
    "$$= -\\frac{1}{m} \\sum_{i=1}^m y_i ln(\\hat{y}_i) + (1-y_i) ln (1-\\hat{y}_i) + \\lambda(|w_1|+...+|w_n|)$$\n",
    "- L2 Error Function: Normally better for training models\n",
    "$$E = -\\frac{1}{m} \\sum_{i=1}^m y_i ln(\\hat{y}_i) + (1-y_i) ln (1-\\hat{y}_i) + \\lambda(w_1^2+...+w_n^2)$$\n",
    "\n",
    "### Dropout\n",
    "Prevent overfitting\n",
    "\n",
    "### Random Restart\n",
    "Jump out the local minima\n",
    "\n",
    "### Vanishing Gradient\n",
    "- Hyperbolic tangent function\n",
    "$$tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$$\n",
    "\n",
    "- Rectified Linear Unit (ReLU)\n",
    "$$\n",
    "relu(x)=\n",
    "\\begin{cases}\n",
    "x & if x\\ge 0\\\\\n",
    "0 & if x<0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### Batch vs Stochastic Gradient Descent\n",
    "Decrease training time\n",
    "\n",
    "### Learning Rate Decay\n",
    "Rule:\n",
    "- If steep: long steps\n",
    "- If plain: small steps\n",
    "\n",
    "### Momentum\n",
    "Solve local minmum problem.\n",
    "- STEP: average of previous steps\n",
    "- $\\beta$: momentum\n",
    "- STEP(n) $\\rightarrow$ STEP(n) + $\\beta$ STEP(n-1) + $\\beta^2$ STEP(n-2) + ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37eba8",
   "metadata": {},
   "source": [
    "## [Deep Learning with TensorFlow](https://github.com/udacity/intro-to-ml-tensorflow)\n",
    "\n",
    "### Build Neural Network\n",
    "[Part 1 Introduction to Neural Networks with TensorFlow](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_1_Introduction_to_Neural_Networks_with_TensorFlow_(Solution).ipynb)\n",
    "\n",
    "[Part 2 Neural networks with TensorFlow and Keras](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_2_Neural_networks_with_TensorFlow_and_Keras_(Solution).ipynb)\n",
    "\n",
    "- `tf.multiply()`: Performs element-wise multiplication on two inputs\n",
    "- `tf.matmul()`: Performs matrix multiplication on two inputs\n",
    "- `tf.reduce_sum()`: Computes the sum of elements across an input tensor's dimensions\n",
    "- `tf.convert_to_tensor()`: convert ndarray to a TensorFlow tensor\n",
    "- `tensor.numpy()`: command on the tensor itself to convert it to an ndarray\n",
    "\n",
    "There are [plenty of different datasets](https://www.tensorflow.org/datasets/catalog/overview) available from the `tensorflow_datasets` library, which we shortened in the code to `tfds`. Loading one of the datasets is simple with the `tfds.load()` function, which takes in the dataset name (in this case `mnist`), as well as some other optional arguments such as: 1) the dataset split to get (training, test, validation), 2) whether to shuffle the data, 3) if the data is to be used as part of a supervised learning algorithm (including labels), 4) whether to include metadata about the dataset itself, and [more](https://www.tensorflow.org/datasets/api_docs/python/tfds/load).\n",
    "\n",
    "You can use the `.take()` function with an integer as an argument to get a certain number of images at once from the dataset.\n",
    "\n",
    "#### Pipelines\n",
    "\n",
    "- [Pipeline Performance](https://www.tensorflow.org/guide/data_performance)\n",
    "- [Transformations](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)\n",
    "\n",
    "#### Softmax\n",
    "\n",
    "To calculate this probability distribution, we often use the [**softmax** function](https://en.wikipedia.org/wiki/Softmax_function). Mathematically this looks like\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "TensorFlow also includes one of its own built-in Softmax activation functions you can use. Using the [TensorFlow API documentation]\n",
    "\n",
    "- `tf.nn.softmax`\n",
    "- `tf.math.softmax`\n",
    "- `tf.keras.activations.softmax`\n",
    "\n",
    "#### Neural Networks with TensorFlow\n",
    "\n",
    "Keras helps further simplify working with neural networks running on TensorFlow under the hood. You can more easily stack layers with `tf.keras.Sequential`, making sure to feed an `input_shape` to the first layer of the network. You can also either add separate `Activation` layers, or feed an activation as an argument within certain layers, such as the `Dense` fully-connected layers.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape = (28,28,1)),\n",
    "        tf.keras.layers.Dense(256, activation = 'sigmoid'),\n",
    "        tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "#### Subclassing\n",
    "```python\n",
    "class Network(tf.keras.Model):\n",
    "    def __init__(self, num_classes = 2):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "        # Define layers \n",
    "        self.input_layer = tf.keras.layers.Flatten()\n",
    "        self.hidden_layer = tf.keras.layers.Dense(256, activation = 'relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(self.num_classes, activation = 'softmax')\n",
    "    \n",
    "    # Define forward Pass   \n",
    "    def call(self, input_tensor):\n",
    "        x = self.input_layer(input_tensor)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "    \n",
    "        return x\n",
    "\n",
    "\n",
    "# Create a model object\n",
    "subclassed_model = Network(10)\n",
    "\n",
    "# Build the model, i.e. initialize the model's weights and biases\n",
    "subclassed_model.build((None, 28, 28, 1))\n",
    "\n",
    "subclassed_model.summary()\n",
    "```\n",
    "\n",
    "#### Adding Layers with .add\n",
    "\n",
    "Example:\n",
    "```python\n",
    "layer_neurons = [512, 256, 128, 56, 28, 14]\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape = (28,28,1)))\n",
    "\n",
    "for neurons in layer_neurons:\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "            \n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "          \n",
    "model.summary() \n",
    "```\n",
    "\n",
    "#### Clearing the Graph\n",
    "\n",
    "In order to avoid clutter from old models in the graph, we can use:\n",
    "\n",
    "```python\n",
    "tf.keras.backend.clear_session()\n",
    "```\n",
    "\n",
    "This command deletes the current `tf.keras` graph and creates a new one.\n",
    "\n",
    "\n",
    "### Train Neural Network\n",
    "[Part 3 Training Neural Networks](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_3_Training_Neural_Networks_(Solution).ipynb)\n",
    "\n",
    "Before we can train our model we need to set the parameters we are going to use to train it. We can configure our model for training using the `.compile` method. The main parameters we need to specify in the `.compile` method are:\n",
    "\n",
    "* **Optimizer:** The algorithm that we'll use to update the weights of our model during training. Throughout these lessons we will use the [`adam`](http://arxiv.org/abs/1412.6980) optimizer. Adam is an optimization of the stochastic gradient descent algorithm. For a full list of the optimizers available in `tf.keras` check out the [optimizers documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers#classes).\n",
    "\n",
    "\n",
    "* **Loss Function:** The loss function we are going to use during training to measure the difference between the true labels of the images in your dataset and the predictions made by your model. In this lesson we will use the `sparse_categorical_crossentropy` loss function. We use the `sparse_categorical_crossentropy` loss function when our dataset has labels that are integers, and the `categorical_crossentropy` loss function when our dataset has one-hot encoded labels. For a full list of the loss functions available in `tf.keras` check out the [losses documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/losses#classes).\n",
    "\n",
    "\n",
    "* **Metrics:** A list of metrics to be evaluated by the model during training. Throughout these lessons we will measure the `accuracy` of our model. The `accuracy` calculates how often our model's predictions match the true labels of the images in our dataset. For a full list of the metrics available in `tf.keras` check out the [metrics documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/metrics#classes).\n",
    "\n",
    "These are the main parameters we are going to set throught these lesson. You can check out all the other configuration parameters in the [TensorFlow documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#compile)\n",
    "\n",
    "Example:\n",
    "```python\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "#### Training the Model\n",
    "\n",
    "Now let's train our model by using all the images in our training set. Some nomenclature, one pass through the entire dataset is called an *epoch*. To train our model for a given number of epochs we use the `.fit` method, as seen below:\n",
    "\n",
    "```python\n",
    "EPOCHS = 5\n",
    "\n",
    "history = model.fit(training_batches, epochs = EPOCHS)\n",
    "```\n",
    "\n",
    "The `.fit` method returns a `History` object which contains a record of training accuracy and loss values at successive epochs, as well as validation accuracy and loss values when applicable. We will discuss the history object in a later lesson. \n",
    "\n",
    "With our model trained, we can check out it's predictions.\n",
    "\n",
    "```python\n",
    "## Build model\n",
    "my_model = tf.keras.Sequential([\n",
    "           tf.keras.layers.Flatten(input_shape = (28,28,1)),\n",
    "           tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "           tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "           tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "           tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "\n",
    "my_model.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "\n",
    "## Train model\n",
    "EPOCHS = 5\n",
    "\n",
    "history = my_model.fit(training_batches, epochs = EPOCHS)\n",
    "\n",
    "\n",
    "## Predict model\n",
    "for image_batch, label_batch in training_batches.take(1):\n",
    "    ps = my_model.predict(image_batch)\n",
    "    first_image = image_batch.numpy().squeeze()[0]\n",
    "```\n",
    "\n",
    "\n",
    "### Train Neural Network on Complex Dataset\n",
    "[Part 4 Fashion MNIST](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_4_Fashion_MNIST_(Solution).ipynb)\n",
    "\n",
    "[Part 5 Inference and Validation](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_5_Inference_and_Validation_(Solution).ipynb)\n",
    "\n",
    "### Inference & Validation\n",
    "\n",
    "We used `tfds.Split.ALL.subsplit` to make a 60/20/20 split for training, validation and test sets, although some TensorFlow datasets have these subsections already built in. Depending on the dataset, you may also want to make sure to shuffle the data at this point as well.\n",
    "\n",
    "Avoid overfitting to the training data?\n",
    "- Stop training when the training and validation curves start to diverge by a certain amount\n",
    "- Save down the best validation accuracy model from during training\n",
    "- Add layers like Dropout to help generalize the network\n",
    "\n",
    "\n",
    "### Saving & Loading\n",
    "[Part 6 Saving and Loading Models](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_6_Saving_and_Loading_Models.ipynb)\n",
    "\n",
    "In TensorFlow we can save our trained models in different formats. Here we will see how to save our models in TensorFlow's SavedModel format and as HDF5 files, which is the format used by Keras models.\n",
    "\n",
    "#### Saving and Loading Models in HDF5 Format\n",
    "\n",
    "To save our models in the format used by Keras models we use the `.save(filepath)` method. For example, to save a model called `my_model` in the current working directory with the name `test_model` we use:\n",
    "\n",
    "```python\n",
    "my_model.save('./test_model.h5')\n",
    "```\n",
    "\n",
    "It's important to note that we have to provide the `.h5` extension to the `filepath` in order the tell `tf.keras` to save our model as an HDF5 file. \n",
    "\n",
    "The above command saves our model into a single HDF5 file that will contain:\n",
    "\n",
    "* The model's architecture.\n",
    "* The model's weight values which were learned during training.\n",
    "* The model's training configuration, which corresponds to the parameters you passed to the `compile` method.\n",
    "* The optimizer and its state. This allows you to resume training exactly where you left off.\n",
    "\n",
    "\n",
    "In the cell below we save our trained `model` as an HDF5 file. The name of our HDF5 will correspond to the current time stamp. This is useful if you are saving many models and want each of them to have a unique name. By default the `.save()` method will **silently** overwrite any existing file at the target location with the same name. If we want `tf.keras` to provide us with a manual prompt to whether overwrite files with the same name, you can set the argument `overwrite=False` in the `.save()` method.\n",
    "\n",
    "```python\n",
    "t = time.time()\n",
    "\n",
    "saved_keras_model_filepath = './{}.h5'.format(int(t))\n",
    "\n",
    "model.save(saved_keras_model_filepath)\n",
    "```\n",
    "\n",
    "Once a model has been saved, we can use `tf.keras.models.load_model(filepath)` to re-load our model. This command will also compile our model automatically using the saved training configuration, unless the model was never compiled in the first place.\n",
    "\n",
    "```python\n",
    "reloaded_keras_model = tf.keras.models.load_model(saved_keras_model_filepath)\n",
    "```\n",
    "\n",
    "#### Saving and Loading TensorFlow SavedModels\n",
    "\n",
    "To export our models to the TensorFlow **SavedModel** format, we use the `tf.saved_model.save(model, export_dir)` function. For example, to save a model called `my_model` in a folder called `saved_models` located in the current working directory we use:\n",
    "\n",
    "```python\n",
    "tf.saved_model.save(my_model, './saved_models')\n",
    "```\n",
    "\n",
    "It's important to note that here we have to provide the path to the directory where we want to save our model, **NOT** the name of the file. This is because SavedModels are not saved in a single file. Rather, when you save your model as a SavedModel, `the tf.saved_model.save()` function will create an `assets` folder, a `variables` folder, and a `saved_model.pb` file inside the directory you provided.\n",
    "\n",
    "The SavedModel files that are created contain:\n",
    "\n",
    "* A TensorFlow checkpoint containing the model weights.\n",
    "* A SavedModel proto containing the underlying TensorFlow graph. Separate graphs are saved for prediction (serving), training, and evaluation. If the model wasn't compiled before, then only the inference graph gets exported.\n",
    "* The model's architecture configuration if available.\n",
    "\n",
    "The SavedModel is a standalone serialization format for TensorFlow objects, supported by TensorFlow serving as well as TensorFlow implementations other than Python. It does not require the original model building code to run, which makes it useful for sharing or deploying in different platforms, such as mobile and embedded devices (with TensorFlow Lite), servers (with TensorFlow Serving), and even web browsers (with TensorFlow.js).\n",
    "\n",
    "In the cell below we save our trained model as a SavedModel. The name of the folder where we are going to save our model will correspond to the current time stamp. Again, this is useful if you are saving many models and want each of them to be saved in a unique directory.\n",
    "\n",
    "```python\n",
    "t = time.time()\n",
    "\n",
    "savedModel_directory = './{}'.format(int(t))\n",
    "\n",
    "tf.saved_model.save(model, savedModel_directory)\n",
    "```\n",
    "\n",
    "Once a model has been saved as a SavedModel, we can use `tf.saved_model.load(export_dir)` to re-load our model. \n",
    "\n",
    "```python\n",
    "reloaded_SavedModel = tf.saved_model.load(savedModel_directory)\n",
    "```\n",
    "\n",
    "It's important to note that the object returned by `tf.saved_model.load` is **NOT** a Keras object. Therefore, it doesn't have `.fit`, `.predict`, `.summary`, etc. methods. It is 100% independent of the code that created it. This means that in order to make predictions with our `reloaded_SavedModel` we need to use a different method than the one used with the re-loaded Keras model.\n",
    "\n",
    "To make predictions on a batch of images with a re-loaded SavedModel we have to use:\n",
    "\n",
    "```python\n",
    "reloaded_SavedModel(image_batch, training=False)\n",
    "```\n",
    "\n",
    "This will return a tensor with the predicted label probabilities for each image in the batch. Again, since we haven't done anything new to this re-loaded SavedModel, then both the `reloaded_SavedModel` and our original `model` should be identical copies. Therefore, they should make the same predictions on the same images.\n",
    "\n",
    "We can also get back a full Keras model, from a TensorFlow SavedModel, by loading our SavedModel with the `tf.keras.models.load_model` function. \n",
    "\n",
    "```python\n",
    "reloaded_keras_model_from_SavedModel = tf.keras.models.load_model(savedModel_directory)\n",
    "```\n",
    "\n",
    "#### Saving Models During Training\n",
    "\n",
    "We have seen that when we train a model with a validation set, the value of the validation loss changes through the training process. Since the value of the validation loss is an indicator of how well our model will generalize to new data, it will be great if could save our model at each step of the training process and then only keep the version with the lowest validation loss. \n",
    "\n",
    "We can do this in `tf.keras` by using the following callback:\n",
    "\n",
    "```python\n",
    "tf.keras.callbacks.ModelCheckpoint('./best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "```\n",
    "This callback will save the model as a Keras HDF5 file after every epoch. With the `save_best_only=True` argument, this callback will first check the validation loss of the latest model against the one previously saved. The callback will only save the latest model and overwrite the old one, if the latest model has a lower validation loss than the one previously saved. This will guarantee that will end up with the version of the model that achieved the lowest validation loss during training.\n",
    "\n",
    "### Loading Images with TensorFlow\n",
    "[Part 7 Loading Image Data](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_7_Loading_Image_Data_(Solution).ipynb)\n",
    "\n",
    "### Data Augmentation\n",
    "`tf.keras` offers many other transformations that we can apply to our images. You can take a look at all the available transformations in the [TensorFlow Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#arguments)\n",
    "\n",
    "* rotation_range\n",
    "* width_shift_range\n",
    "* height_shift_range\n",
    "* shear_range\n",
    "* zoom_range\n",
    "* horizontal_flip\n",
    "* fill_mode\n",
    "\n",
    "### Creating a Validation Data Generator\n",
    "Generally, we only apply data augmentation to our training data. Therefore, for the validation set we only need to normalize the pixel values of our images.\n",
    "\n",
    "### Pre-Notebooks with GPU\n",
    "\n",
    "### Transfer Learning\n",
    "\n",
    "[Transfer Learning](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Transfer%20Learning.pdf)\n",
    "\n",
    "[Part 8 Transfer Learning](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_8_Transfer_Learning_(Solution).ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542be54",
   "metadata": {},
   "source": [
    "## Deep Learning with PyTorch\n",
    "\n",
    "Calculate the output of single layer network using `torch.sum()` or `.sum()` and __matrix multiplication__.\n",
    "\n",
    "### Watch those shapes\n",
    "In general, you'll want to check that the tensors going through your model and other code are the correct shapes. Make use of the `.shape` method during debugging and development.\n",
    "\n",
    "A few things to check if your network isn't training appropriately\n",
    "Make sure you're clearing the gradients in the training loop with `optimizer.zero_grad()`. If you're doing a validation loop, be sure to set the network to evaluation mode with `model.eval()`, then back to training mode with `model.train()`.\n",
    "\n",
    "\n",
    "### CUDA errors\n",
    "Sometimes you'll see this error:\n",
    "\n",
    "```\n",
    "RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #1 ‘mat1’\n",
    "```\n",
    "\n",
    "You'll notice the second type is `torch.cuda.FloatTensor`, this means it's a tensor that has been moved to the GPU. It's expecting a tensor with type `torch.FloatTensor`, no `.cuda` there, which means the tensor should be on the CPU. PyTorch can only perform operations on tensors that are on the same device, so either both CPU or both GPU. If you're trying to run your network on the GPU, check to make sure you've moved the model and all necessary tensors to the GPU with `.to(device)` where `device` is either `\"cuda\"` or `\"cpu\"`.\n",
    "\n",
    "\n",
    "[Tutorial: Deep Learning in PyTorch](http://iamtrask.github.io/2017/01/15/pytorch-tutorial/)\n",
    "\n",
    "[Notebooks](https://github.com/stephengineer/Machine-Learning/tree/main/Deep%20Learning/05%20Deep%20Learning%20with%20PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ae38a",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "### Normalizing image inputs\n",
    "Data normalization is an important pre-processing step. It ensures that each input (each pixel value, in this case) comes from a standard distribution. That is, the range of pixel values in one input image are the same as the range in another image. This standardization makes our model train and reach a minimum error, faster!\n",
    "\n",
    "\n",
    "### ReLU Activation Function\n",
    "The purpose of an activation function is to scale the outputs of a layer so that they are a consistent, small value. Much like normalizing input values, this step ensures that our model trains efficiently!\n",
    "\n",
    "A ReLU activation function stands for \"Rectified Linear Unit\" and is one of the most commonly used activation functions for hidden layers. It is an activation function, simply defined as the __positive__ part of the input, `x`. So, for an input image with any negative pixel values, this would turn all those values to `0`, black. You may hear this referred to as \"clipping\" the values to zero; meaning that is the lower bound.\n",
    "\n",
    "![ReLU](./img/relu-ex.png)\n",
    "\n",
    "\n",
    "### Cross-Entropy Loss\n",
    "In the [PyTorch documentation](https://pytorch.org/docs/stable/nn.html#crossentropyloss), you can see that the cross entropy loss function actually involves two steps:\n",
    "\n",
    "- It first applies a softmax function to any output is sees\n",
    "- Then applies [NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss); negative log likelihood loss\n",
    "\n",
    "Then it returns the average loss over a batch of data. Since it applies a softmax function, we do not have to specify that in the `forward` function of our model definition, but we could do this another way.\n",
    "\n",
    "#### Another approach\n",
    "We could separate the softmax and NLLLoss steps.\n",
    "\n",
    "- In the `forward` function of our model, we would explicitly apply a softmax activation function to the output, `x`.\n",
    "\n",
    "```py\n",
    "# a softmax layer to convert 10 outputs into a distribution of class probabilities\n",
    "x = F.log_softmax(x, dim=1)\n",
    "\n",
    "return x\n",
    "```\n",
    "\n",
    "- Then, when defining our loss criterion, we would apply NLLLoss\n",
    "\n",
    "```py\n",
    "# cross entropy loss combines softmax and nn.NLLLoss() in one single class\n",
    "# here, we've separated them\n",
    "criterion = nn.NLLLoss()\n",
    "```\n",
    "\n",
    "This separates the usual `criterion = nn.CrossEntropy()` into two steps: softmax and NLLLoss, and is a useful approach should you want the output of a model to be class probabilities rather than class scores.\n",
    "\n",
    "\n",
    "### Validation Set: Takeaways\n",
    "\n",
    "Measure how well a model generalizes, during training\n",
    "Tell us when to stop training a model; when the validation loss stops decreasing (and especially when the validation loss starts increasing and the training loss is still decreasing)\n",
    "\n",
    "![imageClassificationSteps](./img/imageClassificationSteps.png)\n",
    "\n",
    "### Filters\n",
    "To detect changes in intensity in an image, you’ll be using and creating specific image filters that look at groups of pixels and react to alternating patterns of dark/light pixels. These filters produce an output that shows edges of objects and differing textures.\n",
    "\n",
    "### Frequency in images\n",
    "We have an intuition of what frequency means when it comes to sound. High-frequency is a high pitched noise, like a bird chirp or violin. And low frequency sounds are low pitch, like a deep voice or a bass drum. For sound, frequency actually refers to how fast a sound wave is oscillating; oscillations are usually measured in cycles/s ([Hz](https://en.wikipedia.org/wiki/Hertz)), and high pitches and made by high-frequency waves. Examples of low and high-frequency sound waves are pictured below. On the y-axis is amplitude, which is a measure of sound pressure that corresponds to the perceived loudness of a sound, and on the x-axis is time.\n",
    "\n",
    "![frequency](./img/frequency.png)\n",
    "\n",
    "#### High and low frequency\n",
    "Similarly, frequency in images is a __rate of change__. But, what does it means for an image to change? Well, images change in space, and a high frequency image is one where the intensity changes a lot. And the level of brightness changes quickly from one pixel to the next. A low frequency image may be one that is relatively uniform in brightness or changes very slowly. This is easiest to see in an example.\n",
    "\n",
    "![frequencyImage](./img/frequencyImage.png)\n",
    "\n",
    "Most images have both high-frequency and low-frequency components. In the image above, on the scarf and striped shirt, we have a high-frequency image pattern; this part changes very rapidly from one brightness to another. Higher up in this same image, we see parts of the sky and background that change very gradually, which is considered a smooth, low-frequency pattern.\n",
    "\n",
    "__High-frequency components also correspond to the edges of objects in images__, which can help us classify those objects.\n",
    "\n",
    "#### Edge Handling\n",
    "Kernel convolution relies on centering a pixel and looking at it's surrounding neighbors. So, what do you do if there are no surrounding pixels like on an image corner or edge? Well, there are a number of ways to process the edges, which are listed below. It’s most common to use padding, cropping, or extension. In extension, the border pixels of an image are copied and extended far enough to result in a filtered image of the same size as the original image.\n",
    "\n",
    "__Extend__ The nearest border pixels are conceptually extended as far as necessary to provide values for the convolution. Corner pixels are extended in 90° wedges. Other edge pixels are extended in lines.\n",
    "\n",
    "__Padding__ The image is padded with a border of 0's, black pixels.\n",
    "\n",
    "__Crop__ Any pixel in the output image which would require values from beyond the edge is skipped. This method can result in the output image being slightly smaller, with the edges having been cropped.\n",
    "\n",
    "### Pooling layers\n",
    "Some architectures choose to use [average pooling](https://pytorch.org/docs/stable/nn.html#avgpool2d), which chooses to average pixel values in a given window size. So in a 2x2 window, this operation will see 4 pixel values, and return a single, average of those four values, as output!\n",
    "\n",
    "This kind of pooling is typically not used for image classification problems because maxpooling is better at noticing the most important details about edges and other features in an image, but you may see this used in applications for which smoothing an image is preferable.\n",
    "\n",
    "### Padding\n",
    "Padding is just adding a border of pixels around an image. In PyTorch, you specify the size of this border.\n",
    "\n",
    "Why do we need padding?\n",
    "\n",
    "When we create a convolutional layer, we move a square filter around an image, using a center-pixel as an anchor. So, this kernel cannot perfectly overlay the edges/corners of images. The nice feature of padding is that it will allow us to control the spatial size of the output volumes (most commonly as we’ll see soon we will use it to exactly preserve the spatial size of the input volume so the input and output width and height are the same).\n",
    "\n",
    "The most common methods of padding are padding an image with all 0-pixels (zero padding) or padding them with the nearest pixel value. You can read more about calculating the amount of padding, given a kernel_size, [here](https://cs231n.github.io/convolutional-networks/#conv).\n",
    "\n",
    "### Formula: Number of Parameters in a Convolutional Layer\n",
    "The number of parameters in a convolutional layer depends on the supplied values of `filters/out_channels`, `kernel_size`, and `input_shape`. Let's define a few variables:\n",
    "\n",
    "- `K` - the number of filters in the convolutional layer\n",
    "- `F` - the height and width of the convolutional filters\n",
    "- `D_in` - the depth of the previous layer\n",
    "Notice that `K` = `out_channels`, and `F` = `kernel_size`. Likewise, `D_in` is the last value in the `input_shape` tuple, typically 1 or 3 (RGB and grayscale, respectively).\n",
    "\n",
    "Since there are `F*F*D_in` weights per filter, and the convolutional layer is composed of `K` filters, the total number of weights in the convolutional layer is `K*F*F*D_in`. Since there is one bias term per filter, the convolutional layer has `K` biases. Thus, the __number of parameters__ in the convolutional layer is given by `K*F*F*D_in + K`.\n",
    "\n",
    "### Formula: Shape of a Convolutional Layer\n",
    "The shape of a convolutional layer depends on the supplied values of `kernel_size`, `input_shape`, `padding`, and `stride`. Let's define a few variables:\n",
    "\n",
    "- `K` - the number of filters in the convolutional layer\n",
    "- `F` - the height and width of the convolutional filters\n",
    "- `S` - the stride of the convolution\n",
    "- `P` - the padding\n",
    "- `W_in` - the width/height (square) of the previous layer\n",
    "Notice that `K = out_channels`, `F = kernel_size`, and `S = stride`. Likewise, `W_in` is the first and second value of the `input_shape` tuple.\n",
    "\n",
    "The __depth__ of the convolutional layer will always equal the number of filters `K`.\n",
    "\n",
    "The spatial dimensions of a convolutional layer can be calculated as: `(W_in−F+2P)/S+1`\n",
    "\n",
    "### Optional Resources\n",
    "- Check out the [AlexNet](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) paper!\n",
    "- Read more about [VGGNet](https://arxiv.org/pdf/1409.1556.pdf) here.\n",
    "- The [ResNet](https://arxiv.org/pdf/1512.03385v1.pdf) paper can be found here.\n",
    "- Here's the [Keras documentation](https://keras.io/api/applications/) for accessing some famous CNN architectures.\n",
    "- Read this [detailed treatment](http://neuralnetworksanddeeplearning.com/chap5.html) of the vanishing gradients problem.\n",
    "- Here's a [GitHub repository](https://github.com/jcjohnson/cnn-benchmarks) containing benchmarks for different CNN architectures.\n",
    "- Visit the [ImageNet Large Scale Visual Recognition Competition (ILSVRC)](https://image-net.org/challenges/LSVRC/) website.\n",
    "\n",
    "### External Resource\n",
    "[Deep learning eBook](https://www.deeplearningbook.org/) (2016) authored by Ian Goodfellow, Yoshua Bengio, and Aaron Courville; published by Cambridge: MIT Press\n",
    "\n",
    "\n",
    "### 3. Transfer Learning\n",
    "Transfer learning involves taking a pre-trained neural network and adapting the neural network to a new, different data set.\n",
    "\n",
    "Depending on both:\n",
    "\n",
    "- The size of the new data set, and\n",
    "- The similarity of the new data set to the original data set\n",
    "\n",
    "The approach for using transfer learning will be different. There are four main cases:\n",
    "\n",
    "1. New data set is small, new data is similar to original training data.\n",
    "2. New data set is small, new data is different from original training data.\n",
    "3. New data set is large, new data is similar to original training data.\n",
    "4. New data set is large, new data is different from original training data.\n",
    "\n",
    "A large data set might have one million images. A small data could have two-thousand images. The dividing line between a large data set and small data set is somewhat subjective. Overfitting is a concern when using transfer learning with a small data set.\n",
    "\n",
    "Images of dogs and images of wolves would be considered similar; the images would share common characteristics. A data set of flower images would be different from a data set of dog images.\n",
    "\n",
    "Each of the four transfer learning cases has its own approach. In the following sections, we will look at each case one by one.\n",
    "\n",
    "\n",
    "### 4. Weight Initialization\n",
    "It's key to include an element of uniqueness, or __randomness__! Better weights might be selected randomly from within a specified range. By adding variety and all unique weight values, we can ensure that backpropagation will have different activations to look at in the hidden layers, and it can respond to those differences.\n",
    "\n",
    "### Additional Material\n",
    "- [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "- [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/pdf/1502.01852v1.pdf)\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167v2.pdf)\n",
    "\n",
    "\n",
    "### 5. Autoencoders\n",
    "\n",
    "Autoencoders are neural networks used for data compression, image de-noising, and dimensionality reduction.\n",
    "\n",
    "\n",
    "### 6. Style Transfer\n",
    "[Image Style Transfer Using Convolutional Neural Networks](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf)\n",
    "\n",
    "Content Loss\n",
    "$$ L_{content} = \\frac{1}{2} \\sum (T_c - C_c)^2 $$\n",
    "\n",
    "Style Loss\n",
    "$$ L_{style} = a \\sum_i w_i (T_{s,i} - s_{s,i})^2 $$\n",
    "\n",
    "Total Loss\n",
    "$$ \\alpha L_{content} + \\beta L_{style} $$\n",
    "\n",
    "The smaller alpha-beta ratio ($\\frac{\\alpha}{\\beta}$), the more stylistic effect you will see.\n",
    "\n",
    "\n",
    "### Project: Landmark Classification & Tagging for Social Media\n",
    "\n",
    "Build a landmark classification and tagging system useful for social media!\n",
    "\n",
    "### 8. Deep Learning in Cancer Detection\n",
    "\n",
    "#### Sensitivity and Specificity\n",
    "\n",
    "[Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "\n",
    "Although similar, sensitivity and specificity are not the same as precision and recall. Here are the definitions:\n",
    "\n",
    "In the cancer example, sensitivity and specificity are the following:\n",
    "\n",
    "- Sensitivity: Of all the people **with** cancer, how many were correctly diagnosed?\n",
    "- Specificity: Of all the people **without** cancer, how many were correctly diagnosed?\n",
    "\n",
    "And precision and recall are the following:\n",
    "\n",
    "- Recall: Of all the people who **have cancer**, how many did **we diagnose** as having cancer?\n",
    "- Precision: Of all the people **we diagnosed** with cancer, how many actually **had cancer**?\n",
    "\n",
    "From here we can see that Sensitivity is Recall, and the other two are not the same thing.\n",
    "\n",
    "Trust me, we also have a hard time remembering which one is which, so here's a little trick. If you remember from Luis's Evaluation Metrics section, here is the confusion matrix:\n",
    "\n",
    "![confusion-matrix](./img/confusion-matrix.png)\n",
    "\n",
    "Now, sensitivity and specificity are the rows of this matrix. More specifically, if we label\n",
    "\n",
    "- TP: (True Positives) Sick people that we **correctly** diagnosed as sick.\n",
    "- TN: (True Negatives) Healthy people that we **correctly** diagnosed as healthy.\n",
    "- FP: (False Positives) Healthy people that we **incorrectly** diagnosed as sick.\n",
    "- FN: (False Negatives) Sick people that we **incorrectly** diagnosed as healthy.\n",
    "then:\n",
    "\n",
    "Sensitivity = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "and\n",
    "\n",
    "Specificity = $\\frac{TN}{TN + FP}$\n",
    "\n",
    "![sensitivity-specificity](./img/sensitivity-specificity.png)\n",
    "\n",
    "<center>Sensitivity and Specificity</center>\n",
    "\n",
    "And precision and recall are the top row and the left column of the matrix:\n",
    "\n",
    "Recall = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "and\n",
    "\n",
    "Precision = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "![precision-recall](./img/precision-recall.png)\n",
    "\n",
    "<center>Precision and Recall</center>\n",
    "\n",
    "The graph below is a histogram of the predictions our model gives in a set of images of lesions, as follows:\n",
    "\n",
    "- Each point in the horizontal axis is a value pp from 0 to 1.\n",
    "- Over each value pp, we locate all the lesions that our classifier predicted to have probability p of being malignant.\n",
    "\n",
    "![threshold](./img/threshold.png)\n",
    "\n",
    "Here we have graphed the thresholds at 0.2, 0.5, and 0.8. Notice how:\n",
    "\n",
    "- At 0.2, we classify every malignant lesion correctly, yet we also send a lot of benign lesions for more testing.\n",
    "- At 0.5, we miss some malignant lesions (bad), and we send a few benign lesions for more testing.\n",
    "- At 0.8, we correctly classify most of the benign lesions, but we miss many malignant lesions (very bad).\n",
    "\n",
    "So in this case, it's arguable that 0.2 is better.\n",
    "\n",
    "\n",
    "#### [ROC Curves](https://www.youtube.com/watch?v=2Iw5TiGzJI4)\n",
    "\n",
    "The curves have been introduced as follows, where in the horizontal axis we plot the True Positive Rate, and in the vertical axis we plot the False Positive Rate.\n",
    "\n",
    "![roc-1](./img/roc-1.png)\n",
    "\n",
    "![roc](./img/roc.png)\n",
    "\n",
    "However, you'll see that in this section, I will use a different ROC Curve. The one I use looks like I flipped it sideways, like this:\n",
    "\n",
    "![roc-curve](./img/roc-curve.png)\n",
    "\n",
    "\n",
    "And there's a really cool reason why I use this one. And it's because it's the curve we get when we plot the sensitivity in the horizontal axis, and the specificity in the vertical axis!\n",
    "\n",
    "Let me be more specific (yes pun intended). Let's use the same histogram as in the last section.\n",
    "\n",
    "![threshold-1](./img/threshold-1.png)\n",
    "\n",
    "Recall that the values in the horizontal axis are all the possible thresholds. For any threshold pp between 0 and 1, the verdict of the model will be the following: \"*Any lesion to the left of this threshold will be considered benign, and any lesion to the right of this threshold will be considered malignant, and sent for more tests*.\"\n",
    "\n",
    "Now, for this particular model, we calculate the sensitivity and specificity as follows:\n",
    "\n",
    "- Sensitivity: Out of all the malignant lesions, what percentage are to the right of the threshold (correctly classified)?\n",
    "- Specificity: Out of all the benign lesions, what percentage are to the left of the threshold (correctly classified)?\n",
    "\n",
    "And we plot that point, where the coordinates are (Sensitivity, Specificity). If we plot all the points corresponding to each of the possible thresholds between 0% and 100%, we'll get the ROC curve that I drew above. Therefore, we can also refer to the ROC curve as the *Sensitivity-Specificity Curve*.\n",
    "\n",
    "And finally, here's a little animation of the ROC curve getting drawn, as the threshold moves from 0 to 1.\n",
    "\n",
    "\n",
    "#### Confusion Matrices\n",
    "\n",
    "In Luis's Evaluation Metrics section, we learned about confusion matrices, and if you need a refresher, the [video](https://www.youtube.com/watch?v=9GLNjmMUB_4).\n",
    "\n",
    "##### Type 1 and Type 2 Errors\n",
    "\n",
    "Sometimes in the literature, you'll see False Positives and True Negatives as Type 1 and Type 2 errors. Here is the correspondence:\n",
    "\n",
    "- **Type 1 Error (Error of the first kind, or False Positive):** In the medical example, this is when we misdiagnose a healthy patient as sick.\n",
    "- **Type 2 Error (Error of the second kind, or False Negative):** In the medical example, this is when we misdiagnose a sick patient as healthy.\n",
    "\n",
    "But confusion matrices can be much larger than 2 X 2. Here's an example of a larger one. Let's say we have three illnesses called A, B, C. And here is a confusion matrix:\n",
    "\n",
    "![new-confusion-matrix](./img/new-confusion-matrix.png)\n",
    "\n",
    "<center>A confusion matrix for three types of illnesses: A, B, and C</center>\n",
    "\n",
    "As you can see, each entry in the ii-th row and the j-th column will tell you the probability of the patient having illness ii and getting diagnosed with illness j.\n",
    "\n",
    "For example, from the entry on the second row and the first column, we can determine that if a patient has illness B, the probability of getting diagnosed with illness A is exactly 0.08.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b57458",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks\n",
    "\n",
    "\n",
    "### 1. Recurrent Neural Networks\n",
    "\n",
    "[Sketch RNN (demo here)](https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html) is a program that learns to complete a drawing, once you give it something (a line or circle, etc.) to start!\n",
    "\n",
    "\n",
    "#### A bit of history\n",
    "RNNs have a key flaw, as capturing relationships that span more than 8 or 10 steps back is practically impossible. This flaw stems from the \"—__vanishing gradient__\" problem in which the contribution of information decays geometrically over time.\n",
    "\n",
    "What does this mean?\n",
    "\n",
    "As you may recall, while training our network we use __backpropagation__. In the backpropagation process we adjust our weight matrices with the use of a __gradient__. In the process, gradients are calculated by continuous multiplications of derivatives. The value of these derivatives may be so small, that these continuous multiplications may cause the gradient to practically \"vanish\".\n",
    "\n",
    "__LSTM__ is one option to overcome the Vanishing Gradient problem in RNNs.\n",
    "\n",
    "Please use these resources if you would like to read more about the [Vanishing Gradient](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) problem or understand further the concept of a [Geometric Series](https://socratic.org/algebra/exponents-and-exponential-functions/geometric-sequences-and-exponential-functions) and how its values may exponentially decrease.\n",
    "\n",
    "If you are still curious, for more information on the important milestones mentioned here, please take a peek at the following links:\n",
    "\n",
    "- [TDNN](https://en.wikipedia.org/wiki/Time_delay_neural_network)\n",
    "- Here is the original [Elman Network](https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog1402_1) publication from 1990. This link is provided here as it's a significant milestone in the world on RNNs. To simplify things a bit, you can take a look at the following [additional info](https://en.wikipedia.org/wiki/Recurrent_neural_network#Elman_networks_and_Jordan_networks).\n",
    "- In this [LSTM](http://www.bioinf.jku.at/publications/older/2604.pdf) link you will find the original paper written by [Sepp Hochreiter](https://en.wikipedia.org/wiki/Sepp_Hochreiter) and [Jürgen Schmidhuber](https://people.idsia.ch//~juergen/). Don't get into all the details just yet. We will cover all of this later!\n",
    "\n",
    "As mentioned in the video, Long Short-Term Memory Cells (LSTMs) and Gated Recurrent Units (GRUs) give a solution to the vanishing gradient problem, by helping us apply networks that have temporal dependencies. In this lesson we will focus on RNNs and continue with LSTMs. We will not be focusing on GRUs. More information about GRUs can be found in the following blog. Focus on the overview titled: __GRUs__.\n",
    "\n",
    "\n",
    "#### Applications\n",
    "There are so many interesting applications, let's look at a few more!\n",
    "\n",
    "- Are you into gaming and bots? Check out the [DotA 2 bot by Open AI](https://openai.com/blog/dota-2/)\n",
    "- How about [automatically adding sounds to silent movies?](https://www.youtube.com/watch?time_continue=1&v=0FW99AQmMc8)\n",
    "- Here is a cool tool for [automatic handwriting generation]()\n",
    "- Amazon's voice to text using high quality speech recognition, [Amazon Lex](https://aws.amazon.com/lex/faqs/).\n",
    "- Facebook uses RNN and LSTM technologies for [building language models](https://engineering.fb.com/2016/10/25/ml-applications/building-an-efficient-neural-language-model-over-a-billion-words/)\n",
    "- Netflix also uses RNN models: [here is an interesting read](https://arxiv.org/pdf/1511.06939.pdf)\n",
    "\n",
    "\n",
    "#### Feedforward Neural Network - A Reminder\n",
    "The mathematical calculations needed for training RNN systems are fascinating. To deeply understand the process, we first need to feel confident with the vanilla FFNN system. We need to thoroughly understand the feedforward process, as well as the backpropagation process used in the training phases of such systems. The next few videos will cover these topics, which you are already familiar with. We will address the feedforward process as well as backpropagation, using specific examples. These examples will serve as extra content to help further understand RNNs later in this lesson.\n",
    "\n",
    "The following couple of videos will give you a brief overview of the __Feedforward Neural Network (FFNN)__.\n",
    "\n",
    "As mentioned before, when working with neural networks we have 2 primary phases: __Training__ and __Evaluation__.\n",
    "\n",
    "During the __training__ phase, we take the data set (also called the training set), which includes many pairs of inputs and their corresponding targets (outputs). Our goal is to find a set of weights that would best map the inputs to the desired outputs. In the __evaluation__ phase, we use the network that was created in the training phase, apply our new inputs and expect to obtain the desired outputs.\n",
    "\n",
    "The training phase will include two steps: __Feedforward__ and __Backpropagation__\n",
    "\n",
    "We will repeat these steps as many times as we need until we decide that our system has reached the best set of weights, giving us the best possible outputs.\n",
    "\n",
    "The next two videos will focus on the feedforward process.\n",
    "\n",
    "You will notice that in these videos I use subscripts as well as superscript as a numeric notation for the weight matrix.\n",
    "\n",
    "For example:\n",
    "\n",
    "- $W_k$ is weight matrix k\n",
    "- $W_{ij}^{k}$ is the ij element of weight matrix k\n",
    "\n",
    "\n",
    "#### Feedforward\n",
    "In this section we will look closely at the math behind the feedforward process. With the use of basic Linear Algebra tools, these calculations are pretty simple!\n",
    "\n",
    "If you are not feeling confident with linear combinations and matrix multiplications, you can use the following links as a refresher:\n",
    "\n",
    "- [Linear Combination](http://linear.ups.edu/html/section-LC.html)\n",
    "- [Matrix Multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication)\n",
    "\n",
    "Assuming that we have a single hidden layer, we will need two steps in our calculations. The first will be calculating the value of the hidden states and the latter will be calculating the value of the outputs.\n",
    "\n",
    "Notice that both the hidden layer and the output layer are displayed as vectors, as they are both represented by more than a single neuron.\n",
    "\n",
    "##### Calculating the value of the hidden states\n",
    "\n",
    "[Video](https://youtu.be/4rCfnWbx8-0)\n",
    "\n",
    "vector h' of the hidden layer will be calculated by multiplying the input vector with the weight matrix $W^{1}$ the following way: $\\bar{h'}=(\\bar{x}W^1)$ Using vector by matrix multiplication.\n",
    "\n",
    "After finding h' we need an activation function $\\Phi$ to finalize the computation of the hidden layer's values. This activation function can be a Hyperbolic Tangent, a Sigmoid or a ReLU function. We can use the following two equations to express the final hidden vector $\\bar{h}$: $\\bar{h}=\\Phi(\\bar{x}W^1)$ or $\\bar{h}=\\Phi(h')$\n",
    "\n",
    "\n",
    "More information on the activation functions and how to use them can be found [here](https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions)\n",
    "\n",
    "\n",
    "##### Calculating the values of the Outputs.\n",
    "\n",
    "[Video](https://youtu.be/kTYbTVh1d0k)\n",
    "\n",
    "The process of calculating the output vector is mathematically similar to that of calculating the vector of the hidden layer. We use, again, a vector by matrix multiplication, which can be followed by an activation function. The vector is the newly calculated hidden layer and the matrix is the one connecting the hidden layer to the output.\n",
    "\n",
    "Essentially, each new layer in an neural network is calculated by a vector by matrix multiplication, where the vector represents the inputs to the new layer and the matrix is the one connecting these new inputs to the next layer.\n",
    "\n",
    "In our example, the input vector is $\\bar{h}$ and the matrix is $W^2$, therefore $\\bar{y}=\\bar{h}W^2$. In some applications it can be beneficial to use a softmax function (if we want all output values to be between zero and 1, and their sum to be 1).\n",
    "\n",
    "The two error functions that are most commonly used are the [Mean Squared Error (MSE)](https://en.wikipedia.org/wiki/Mean_squared_error) (usually used in regression problems) and the [cross entropy](https://www.ics.uci.edu/~pjsadows/notes.pdf) (usually used in classification problems).\n",
    "\n",
    "In the above calculations we used a variation of the MSE.\n",
    "\n",
    "The next few videos will focus on the backpropagation process, or what we also call stochastic gradient decent with the use of the chain rule.\n",
    " \n",
    " \n",
    "\n",
    "### 2. Long Short-Term Memory Networks (LSTMs)\n",
    "\n",
    "\n",
    "### 3. Implementation of RNN and LSTM\n",
    "\n",
    "\n",
    "### 4. Hyperparameters\n",
    "\n",
    "\n",
    "### 5. Embeddings & Word2Vec\n",
    "\n",
    "\n",
    "### 6. Sentiment Prediction RNN\n",
    "\n",
    "\n",
    "### Project: Generate TV Scripts\n",
    "\n",
    "\n",
    "### 8. Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2688b8",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks\n",
    "\n",
    "\n",
    "### 1. Generative Adversarial Networks\n",
    "\n",
    "\n",
    "### 2. Deep Convolutional GANs\n",
    "\n",
    "\n",
    "### 3. Pix2Pix & CycleGAN\n",
    "\n",
    "\n",
    "### 4. Implementing a CycleGAN\n",
    "\n",
    "\n",
    "### Project: Generate Faces\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e34d34",
   "metadata": {},
   "source": [
    "## Deploying a Model\n",
    "\n",
    "\n",
    "### 1. Introduction to Deployment\n",
    "\n",
    "\n",
    "### 2. Building a Model using SageMaker\n",
    "\n",
    "\n",
    "### 3. Deploying and Using Model\n",
    "\n",
    "\n",
    "### 4. Hyperparameter Tuning\n",
    "\n",
    "\n",
    "### 5. Updating a Model\n",
    "\n",
    "\n",
    "### Project: Deploying a Sentiment Analysis Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1d03c",
   "metadata": {},
   "source": [
    "## Projects\n",
    "\n",
    "- [Sentiment Analysis](https://github.com/stephengineer/Machine-Learning/tree/main/Deep%20Learning/Projects/00%20Sentiment%20Analysis)\n",
    "- [ImageClassifier](https://github.com/stephengineer/Machine-Learning/tree/main/Deep%20Learning/Projects/01%20Image%20Classifier)\n",
    "- [Predicting Bike-Sharing Patterns](https://github.com/stephengineer/Machine-Learning/tree/main/Deep%20Learning/Projects/02%20Bike-Sharing%20Patterns)\n",
    "- [Landmark Classification](https://github.com/stephengineer/Machine-Learning/tree/main/Deep%20Learning/Projects/03%20Landmark%20Classification%20and%20Tagging%20for%20Social%20Media)\n",
    "- [Dermatologist AI](https://github.com/udacity/dermatologist-ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0eebeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
