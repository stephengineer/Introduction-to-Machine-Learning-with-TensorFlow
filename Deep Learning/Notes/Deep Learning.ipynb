{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd884ce9",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "## Github Repos\n",
    "\n",
    "- [Deep Learning](https://github.com/udacity/deep-learning)\n",
    "- [Deep Learning with Pytorch](https://github.com/udacity/deep-learning-v2-pytorch)\n",
    "\n",
    "## Content\n",
    "\n",
    "1. [Introductioin to Neural Networks](#Introductioin-to-Neural-Networks)\n",
    "2. [Implementing Gradient Descent](#Implementing-Gradient-Descent)\n",
    "3. [Training Neural Network](#Training-Neural-Network)\n",
    "4. [Deep Learning with TensorFlow](#Deep-Learning-with-TensorFlow)\n",
    "5. [Deep Learning with PyTorch](#Deep-Learning-with-PyTorch)\n",
    "6. [Convolutional Neural Networks](#Convolutional-Neural-Networks)\n",
    "7. [Projects](#Projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60da5e67",
   "metadata": {},
   "source": [
    "## Introductioin to Neural Networks\n",
    "\n",
    "### Gradient Descent\n",
    "[Principles and the math behind the gradient descent algorithm](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/Introduction%20to%20Neural%20Networks/Gradient%20Descent.pdf)\n",
    "\n",
    "#### Error Function\n",
    "\n",
    "- The error function should be differentiable\n",
    "- THe error function should be continuous\n",
    "\n",
    "### Activation Function\n",
    "\n",
    "#### Gradient Descent Algorithm\n",
    "\n",
    "- Sigmoid activation function\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "- Derivative of the sigmoid function\n",
    "$$\\sigma'(x)=\\sigma(x)(1-\\sigma(x))$$\n",
    "\n",
    "- Output (prediction) formula\n",
    "\n",
    "$$\\hat{y} = \\sigma(w_1 x_1 + w_2 x_2 + b)$$\n",
    "\n",
    "- Error function\n",
    "\n",
    "$$Error(y, \\hat{y}) = - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})$$\n",
    "\n",
    "- The function that updates the weights\n",
    "\n",
    "$$ w_i \\longrightarrow w_i + \\alpha (y - \\hat{y}) x_i$$\n",
    "\n",
    "$$ b \\longrightarrow b + \\alpha (y - \\hat{y})$$\n",
    "\n",
    "\n",
    "```python\n",
    "# Activation (sigmoid) function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def output_formula(features, weights, bias):\n",
    "    return sigmoid(np.dot(features, weights) + bias)\n",
    "\n",
    "def error_formula(y, output):\n",
    "    return - y*np.log(output) - (1 - y) * np.log(1-output)\n",
    "\n",
    "def update_weights(x, y, weights, bias, learnrate):\n",
    "    output = output_formula(x, weights, bias)\n",
    "    d_error = y - output\n",
    "    weights += learnrate * d_error * x\n",
    "    bias += learnrate * d_error\n",
    "    return weights, bias\n",
    "```\n",
    "\n",
    "### One-hot Encoding\n",
    "Use the `get_dummies` function in Pandas in order to one-hot encode the data.\n",
    "\n",
    "```python\n",
    "# Make dummy variables for rank\n",
    "one_hot_data = pd.concat([data, pd.get_dummies(data['rank'], prefix='rank')], axis=1)\n",
    "```\n",
    "\n",
    "### Maximum Likelihood\n",
    "- log(ab) = log(a) + log(b)\n",
    "\n",
    "### Cross Entropy\n",
    "A higher cross-entropy implies a lower probability for an event. (cross-entropy is inversely proportional to the total probability of an outcome.)\n",
    "\n",
    "- A good model gives a low cross entropy\n",
    "- A bad model gives a high cross entropy\n",
    "\n",
    "$$\n",
    "CE = - \\sum_{i=1}^m y_i ln(p_i) + (1-y_i) ln (1-p_i)\n",
    "$$\n",
    "\n",
    "#### Coding Cross-entropy\n",
    "```python\n",
    "# Y is for the category, and P is the probability.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cross_entropy(Y, P):\n",
    "    Y = np.float_(Y)\n",
    "    P = np.float_(P)\n",
    "    return -np.sum(Y * np.log(P) + (1 - Y) * np.log(1 - P))\n",
    "```\n",
    "\n",
    "### Logistic Regression\n",
    "1. Start with random weights: $w_1, ... , w_n, b$\n",
    "2. For every point $(x_1, ... , x_n)$: update $w_i, b$\n",
    "3. Reapeat until error is small\n",
    "\n",
    "### Neural Network Architecture\n",
    "- Input Layer\n",
    "- Hidden Layer\n",
    "- Output Layer\n",
    "\n",
    "### Feedforward\n",
    "\n",
    "### Backpropagation\n",
    "- Doing a feedforward operation.\n",
    "- Comparing the output of the model with the desired output.\n",
    "- Calculating the error.\n",
    "- Running the feedforward operation backwards (backpropagation) to spread the error to each of the weights.\n",
    "- Use this to update the weights, and get a better model.\n",
    "- Continue this until we have a model that is good.\n",
    "\n",
    "#### Backpropagate the error\n",
    "$$ (y-\\hat{y}) \\sigma'(x) $$\n",
    "\n",
    "```python\n",
    "def error_term_formula(x, y, output):\n",
    "    return (y - output)*sigmoid_prime(x)\n",
    "```\n",
    "\n",
    "[Lab: Analyzing Student Data](../../notebooks/01%20Introduction%20to%20Neural%20Networks/StudentAdmissions.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74087f",
   "metadata": {},
   "source": [
    "## Implementing Gradient Descent\n",
    "\n",
    "### Mean Squared Error Function\n",
    "$$\n",
    "E=\\frac{1}{2m}\\sum_{\\mu}(y^{\\mu}-\\hat{y}^{\\mu})^2\n",
    "$$\n",
    "\n",
    "- [Gradient Descent](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Gradient%20Descent.pdf)\n",
    "- [Gradient Descent Code](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Gradient%20Descent%20Code.pdf)\n",
    "- [Gradient Descent Implementing](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Gradient%20Descent%20Implementing.pdf)\n",
    "- [Multilayer Perceptrons](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Multilayer%20Perceptrons.pdf)\n",
    "- [Backpropagation](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Backpropagation.pdf)\n",
    "- [Backpropagation Implementing](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/02%20Implementing%20Gradient%20Descent/Backpropagation%20Implementing.pdf)\n",
    "\n",
    "Further reading\n",
    "- From Andrej Karpathy: [Yes, you should understand backprop](https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b#.vt3ax2kg9)\n",
    "- Also from Andrej Karpathy, [a lecture from Stanford's CS231n course](https://www.youtube.com/watch?v=59Hbtz7XgjM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6672e0",
   "metadata": {},
   "source": [
    "## Training Neural Network\n",
    "\n",
    "### Overfitting and Underfitting\n",
    "\n",
    "- Overfitting -> high variance\n",
    "- Underfitting -> high bias\n",
    "\n",
    "![earlyStopping](./img/earlyStopping.png)\n",
    "\n",
    "### Regularization\n",
    "Large coefficients -> overfitting\n",
    "- L1 Error Function: Good for feature selection\n",
    "$$= -\\frac{1}{m} \\sum_{i=1}^m y_i ln(\\hat{y}_i) + (1-y_i) ln (1-\\hat{y}_i) + \\lambda(|w_1|+...+|w_n|)$$\n",
    "- L2 Error Function: Normally better for training models\n",
    "$$E = -\\frac{1}{m} \\sum_{i=1}^m y_i ln(\\hat{y}_i) + (1-y_i) ln (1-\\hat{y}_i) + \\lambda(w_1^2+...+w_n^2)$$\n",
    "\n",
    "### Dropout\n",
    "Prevent overfitting\n",
    "\n",
    "### Random Restart\n",
    "Jump out the local minima\n",
    "\n",
    "### Vanishing Gradient\n",
    "- Hyperbolic tangent function\n",
    "$$tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$$\n",
    "\n",
    "- Rectified Linear Unit (ReLU)\n",
    "$$\n",
    "relu(x)=\n",
    "\\begin{cases}\n",
    "x & if x\\ge 0\\\\\n",
    "0 & if x<0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### Batch vs Stochastic Gradient Descent\n",
    "Decrease training time\n",
    "\n",
    "### Learning Rate Decay\n",
    "Rule:\n",
    "- If steep: long steps\n",
    "- If plain: small steps\n",
    "\n",
    "### Momentum\n",
    "Solve local minmum problem.\n",
    "- STEP: average of previous steps\n",
    "- $\\beta$: momentum\n",
    "- STEP(n) $\\rightarrow$ STEP(n) + $\\beta$ STEP(n-1) + $\\beta^2$ STEP(n-2) + ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37eba8",
   "metadata": {},
   "source": [
    "## [Deep Learning with TensorFlow](https://github.com/udacity/intro-to-ml-tensorflow)\n",
    "\n",
    "### Build Neural Network\n",
    "[Part 1 Introduction to Neural Networks with TensorFlow](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_1_Introduction_to_Neural_Networks_with_TensorFlow_(Solution).ipynb)\n",
    "\n",
    "[Part 2 Neural networks with TensorFlow and Keras](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_2_Neural_networks_with_TensorFlow_and_Keras_(Solution).ipynb)\n",
    "\n",
    "- `tf.multiply()`: Performs element-wise multiplication on two inputs\n",
    "- `tf.matmul()`: Performs matrix multiplication on two inputs\n",
    "- `tf.reduce_sum()`: Computes the sum of elements across an input tensor's dimensions\n",
    "- `tf.convert_to_tensor()`: convert ndarray to a TensorFlow tensor\n",
    "- `tensor.numpy()`: command on the tensor itself to convert it to an ndarray\n",
    "\n",
    "There are [plenty of different datasets](https://www.tensorflow.org/datasets/catalog/overview) available from the `tensorflow_datasets` library, which we shortened in the code to `tfds`. Loading one of the datasets is simple with the `tfds.load()` function, which takes in the dataset name (in this case `mnist`), as well as some other optional arguments such as: 1) the dataset split to get (training, test, validation), 2) whether to shuffle the data, 3) if the data is to be used as part of a supervised learning algorithm (including labels), 4) whether to include metadata about the dataset itself, and [more](https://www.tensorflow.org/datasets/api_docs/python/tfds/load).\n",
    "\n",
    "You can use the `.take()` function with an integer as an argument to get a certain number of images at once from the dataset.\n",
    "\n",
    "#### Pipelines\n",
    "\n",
    "- [Pipeline Performance](https://www.tensorflow.org/guide/data_performance)\n",
    "- [Transformations](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)\n",
    "\n",
    "#### Softmax\n",
    "\n",
    "To calculate this probability distribution, we often use the [**softmax** function](https://en.wikipedia.org/wiki/Softmax_function). Mathematically this looks like\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "TensorFlow also includes one of its own built-in Softmax activation functions you can use. Using the [TensorFlow API documentation]\n",
    "\n",
    "- `tf.nn.softmax`\n",
    "- `tf.math.softmax`\n",
    "- `tf.keras.activations.softmax`\n",
    "\n",
    "#### Neural Networks with TensorFlow\n",
    "\n",
    "Keras helps further simplify working with neural networks running on TensorFlow under the hood. You can more easily stack layers with `tf.keras.Sequential`, making sure to feed an `input_shape` to the first layer of the network. You can also either add separate `Activation` layers, or feed an activation as an argument within certain layers, such as the `Dense` fully-connected layers.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape = (28,28,1)),\n",
    "        tf.keras.layers.Dense(256, activation = 'sigmoid'),\n",
    "        tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "#### Subclassing\n",
    "```python\n",
    "class Network(tf.keras.Model):\n",
    "    def __init__(self, num_classes = 2):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "        # Define layers \n",
    "        self.input_layer = tf.keras.layers.Flatten()\n",
    "        self.hidden_layer = tf.keras.layers.Dense(256, activation = 'relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(self.num_classes, activation = 'softmax')\n",
    "    \n",
    "    # Define forward Pass   \n",
    "    def call(self, input_tensor):\n",
    "        x = self.input_layer(input_tensor)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "    \n",
    "        return x\n",
    "\n",
    "\n",
    "# Create a model object\n",
    "subclassed_model = Network(10)\n",
    "\n",
    "# Build the model, i.e. initialize the model's weights and biases\n",
    "subclassed_model.build((None, 28, 28, 1))\n",
    "\n",
    "subclassed_model.summary()\n",
    "```\n",
    "\n",
    "#### Adding Layers with .add\n",
    "\n",
    "Example:\n",
    "```python\n",
    "layer_neurons = [512, 256, 128, 56, 28, 14]\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape = (28,28,1)))\n",
    "\n",
    "for neurons in layer_neurons:\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "            \n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "          \n",
    "model.summary() \n",
    "```\n",
    "\n",
    "#### Clearing the Graph\n",
    "\n",
    "In order to avoid clutter from old models in the graph, we can use:\n",
    "\n",
    "```python\n",
    "tf.keras.backend.clear_session()\n",
    "```\n",
    "\n",
    "This command deletes the current `tf.keras` graph and creates a new one.\n",
    "\n",
    "\n",
    "### Train Neural Network\n",
    "[Part 3 Training Neural Networks](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_3_Training_Neural_Networks_(Solution).ipynb)\n",
    "\n",
    "Before we can train our model we need to set the parameters we are going to use to train it. We can configure our model for training using the `.compile` method. The main parameters we need to specify in the `.compile` method are:\n",
    "\n",
    "* **Optimizer:** The algorithm that we'll use to update the weights of our model during training. Throughout these lessons we will use the [`adam`](http://arxiv.org/abs/1412.6980) optimizer. Adam is an optimization of the stochastic gradient descent algorithm. For a full list of the optimizers available in `tf.keras` check out the [optimizers documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers#classes).\n",
    "\n",
    "\n",
    "* **Loss Function:** The loss function we are going to use during training to measure the difference between the true labels of the images in your dataset and the predictions made by your model. In this lesson we will use the `sparse_categorical_crossentropy` loss function. We use the `sparse_categorical_crossentropy` loss function when our dataset has labels that are integers, and the `categorical_crossentropy` loss function when our dataset has one-hot encoded labels. For a full list of the loss functions available in `tf.keras` check out the [losses documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/losses#classes).\n",
    "\n",
    "\n",
    "* **Metrics:** A list of metrics to be evaluated by the model during training. Throughout these lessons we will measure the `accuracy` of our model. The `accuracy` calculates how often our model's predictions match the true labels of the images in our dataset. For a full list of the metrics available in `tf.keras` check out the [metrics documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/metrics#classes).\n",
    "\n",
    "These are the main parameters we are going to set throught these lesson. You can check out all the other configuration parameters in the [TensorFlow documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#compile)\n",
    "\n",
    "Example:\n",
    "```python\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "#### Training the Model\n",
    "\n",
    "Now let's train our model by using all the images in our training set. Some nomenclature, one pass through the entire dataset is called an *epoch*. To train our model for a given number of epochs we use the `.fit` method, as seen below:\n",
    "\n",
    "```python\n",
    "EPOCHS = 5\n",
    "\n",
    "history = model.fit(training_batches, epochs = EPOCHS)\n",
    "```\n",
    "\n",
    "The `.fit` method returns a `History` object which contains a record of training accuracy and loss values at successive epochs, as well as validation accuracy and loss values when applicable. We will discuss the history object in a later lesson. \n",
    "\n",
    "With our model trained, we can check out it's predictions.\n",
    "\n",
    "```python\n",
    "## Build model\n",
    "my_model = tf.keras.Sequential([\n",
    "           tf.keras.layers.Flatten(input_shape = (28,28,1)),\n",
    "           tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "           tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "           tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "           tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "\n",
    "my_model.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "\n",
    "## Train model\n",
    "EPOCHS = 5\n",
    "\n",
    "history = my_model.fit(training_batches, epochs = EPOCHS)\n",
    "\n",
    "\n",
    "## Predict model\n",
    "for image_batch, label_batch in training_batches.take(1):\n",
    "    ps = my_model.predict(image_batch)\n",
    "    first_image = image_batch.numpy().squeeze()[0]\n",
    "```\n",
    "\n",
    "\n",
    "### Train Neural Network on Complex Dataset\n",
    "[Part 4 Fashion MNIST](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_4_Fashion_MNIST_(Solution).ipynb)\n",
    "\n",
    "[Part 5 Inference and Validation](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_5_Inference_and_Validation_(Solution).ipynb)\n",
    "\n",
    "### Inference & Validation\n",
    "\n",
    "We used `tfds.Split.ALL.subsplit` to make a 60/20/20 split for training, validation and test sets, although some TensorFlow datasets have these subsections already built in. Depending on the dataset, you may also want to make sure to shuffle the data at this point as well.\n",
    "\n",
    "Avoid overfitting to the training data?\n",
    "- Stop training when the training and validation curves start to diverge by a certain amount\n",
    "- Save down the best validation accuracy model from during training\n",
    "- Add layers like Dropout to help generalize the network\n",
    "\n",
    "\n",
    "### Saving & Loading\n",
    "[Part 6 Saving and Loading Models](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_6_Saving_and_Loading_Models.ipynb)\n",
    "\n",
    "In TensorFlow we can save our trained models in different formats. Here we will see how to save our models in TensorFlow's SavedModel format and as HDF5 files, which is the format used by Keras models.\n",
    "\n",
    "#### Saving and Loading Models in HDF5 Format\n",
    "\n",
    "To save our models in the format used by Keras models we use the `.save(filepath)` method. For example, to save a model called `my_model` in the current working directory with the name `test_model` we use:\n",
    "\n",
    "```python\n",
    "my_model.save('./test_model.h5')\n",
    "```\n",
    "\n",
    "It's important to note that we have to provide the `.h5` extension to the `filepath` in order the tell `tf.keras` to save our model as an HDF5 file. \n",
    "\n",
    "The above command saves our model into a single HDF5 file that will contain:\n",
    "\n",
    "* The model's architecture.\n",
    "* The model's weight values which were learned during training.\n",
    "* The model's training configuration, which corresponds to the parameters you passed to the `compile` method.\n",
    "* The optimizer and its state. This allows you to resume training exactly where you left off.\n",
    "\n",
    "\n",
    "In the cell below we save our trained `model` as an HDF5 file. The name of our HDF5 will correspond to the current time stamp. This is useful if you are saving many models and want each of them to have a unique name. By default the `.save()` method will **silently** overwrite any existing file at the target location with the same name. If we want `tf.keras` to provide us with a manual prompt to whether overwrite files with the same name, you can set the argument `overwrite=False` in the `.save()` method.\n",
    "\n",
    "```python\n",
    "t = time.time()\n",
    "\n",
    "saved_keras_model_filepath = './{}.h5'.format(int(t))\n",
    "\n",
    "model.save(saved_keras_model_filepath)\n",
    "```\n",
    "\n",
    "Once a model has been saved, we can use `tf.keras.models.load_model(filepath)` to re-load our model. This command will also compile our model automatically using the saved training configuration, unless the model was never compiled in the first place.\n",
    "\n",
    "```python\n",
    "reloaded_keras_model = tf.keras.models.load_model(saved_keras_model_filepath)\n",
    "```\n",
    "\n",
    "#### Saving and Loading TensorFlow SavedModels\n",
    "\n",
    "To export our models to the TensorFlow **SavedModel** format, we use the `tf.saved_model.save(model, export_dir)` function. For example, to save a model called `my_model` in a folder called `saved_models` located in the current working directory we use:\n",
    "\n",
    "```python\n",
    "tf.saved_model.save(my_model, './saved_models')\n",
    "```\n",
    "\n",
    "It's important to note that here we have to provide the path to the directory where we want to save our model, **NOT** the name of the file. This is because SavedModels are not saved in a single file. Rather, when you save your model as a SavedModel, `the tf.saved_model.save()` function will create an `assets` folder, a `variables` folder, and a `saved_model.pb` file inside the directory you provided.\n",
    "\n",
    "The SavedModel files that are created contain:\n",
    "\n",
    "* A TensorFlow checkpoint containing the model weights.\n",
    "* A SavedModel proto containing the underlying TensorFlow graph. Separate graphs are saved for prediction (serving), training, and evaluation. If the model wasn't compiled before, then only the inference graph gets exported.\n",
    "* The model's architecture configuration if available.\n",
    "\n",
    "The SavedModel is a standalone serialization format for TensorFlow objects, supported by TensorFlow serving as well as TensorFlow implementations other than Python. It does not require the original model building code to run, which makes it useful for sharing or deploying in different platforms, such as mobile and embedded devices (with TensorFlow Lite), servers (with TensorFlow Serving), and even web browsers (with TensorFlow.js).\n",
    "\n",
    "In the cell below we save our trained model as a SavedModel. The name of the folder where we are going to save our model will correspond to the current time stamp. Again, this is useful if you are saving many models and want each of them to be saved in a unique directory.\n",
    "\n",
    "```python\n",
    "t = time.time()\n",
    "\n",
    "savedModel_directory = './{}'.format(int(t))\n",
    "\n",
    "tf.saved_model.save(model, savedModel_directory)\n",
    "```\n",
    "\n",
    "Once a model has been saved as a SavedModel, we can use `tf.saved_model.load(export_dir)` to re-load our model. \n",
    "\n",
    "```python\n",
    "reloaded_SavedModel = tf.saved_model.load(savedModel_directory)\n",
    "```\n",
    "\n",
    "It's important to note that the object returned by `tf.saved_model.load` is **NOT** a Keras object. Therefore, it doesn't have `.fit`, `.predict`, `.summary`, etc. methods. It is 100% independent of the code that created it. This means that in order to make predictions with our `reloaded_SavedModel` we need to use a different method than the one used with the re-loaded Keras model.\n",
    "\n",
    "To make predictions on a batch of images with a re-loaded SavedModel we have to use:\n",
    "\n",
    "```python\n",
    "reloaded_SavedModel(image_batch, training=False)\n",
    "```\n",
    "\n",
    "This will return a tensor with the predicted label probabilities for each image in the batch. Again, since we haven't done anything new to this re-loaded SavedModel, then both the `reloaded_SavedModel` and our original `model` should be identical copies. Therefore, they should make the same predictions on the same images.\n",
    "\n",
    "We can also get back a full Keras model, from a TensorFlow SavedModel, by loading our SavedModel with the `tf.keras.models.load_model` function. \n",
    "\n",
    "```python\n",
    "reloaded_keras_model_from_SavedModel = tf.keras.models.load_model(savedModel_directory)\n",
    "```\n",
    "\n",
    "#### Saving Models During Training\n",
    "\n",
    "We have seen that when we train a model with a validation set, the value of the validation loss changes through the training process. Since the value of the validation loss is an indicator of how well our model will generalize to new data, it will be great if could save our model at each step of the training process and then only keep the version with the lowest validation loss. \n",
    "\n",
    "We can do this in `tf.keras` by using the following callback:\n",
    "\n",
    "```python\n",
    "tf.keras.callbacks.ModelCheckpoint('./best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "```\n",
    "This callback will save the model as a Keras HDF5 file after every epoch. With the `save_best_only=True` argument, this callback will first check the validation loss of the latest model against the one previously saved. The callback will only save the latest model and overwrite the old one, if the latest model has a lower validation loss than the one previously saved. This will guarantee that will end up with the version of the model that achieved the lowest validation loss during training.\n",
    "\n",
    "### Loading Images with TensorFlow\n",
    "[Part 7 Loading Image Data](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_7_Loading_Image_Data_(Solution).ipynb)\n",
    "\n",
    "### Data Augmentation\n",
    "`tf.keras` offers many other transformations that we can apply to our images. You can take a look at all the available transformations in the [TensorFlow Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#arguments)\n",
    "\n",
    "* rotation_range\n",
    "* width_shift_range\n",
    "* height_shift_range\n",
    "* shear_range\n",
    "* zoom_range\n",
    "* horizontal_flip\n",
    "* fill_mode\n",
    "\n",
    "### Creating a Validation Data Generator\n",
    "Generally, we only apply data augmentation to our training data. Therefore, for the validation set we only need to normalize the pixel values of our images.\n",
    "\n",
    "### Pre-Notebooks with GPU\n",
    "\n",
    "### Transfer Learning\n",
    "\n",
    "[Transfer Learning](https://github.com/stephengineer/Introduction-to-Machine-Learning-with-TensorFlow/blob/main/Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Transfer%20Learning.pdf)\n",
    "\n",
    "[Part 8 Transfer Learning](../../Deep%20Learning/04%20Deep%20Learning%20with%20TensorFlow/Notebooks/Part_8_Transfer_Learning_(Solution).ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542be54",
   "metadata": {},
   "source": [
    "## Deep Learning with PyTorch\n",
    "\n",
    "Calculate the output of single layer network using `torch.sum()` or `.sum()` and __matrix multiplication__.\n",
    "\n",
    "### Watch those shapes\n",
    "In general, you'll want to check that the tensors going through your model and other code are the correct shapes. Make use of the `.shape` method during debugging and development.\n",
    "\n",
    "A few things to check if your network isn't training appropriately\n",
    "Make sure you're clearing the gradients in the training loop with `optimizer.zero_grad()`. If you're doing a validation loop, be sure to set the network to evaluation mode with `model.eval()`, then back to training mode with `model.train()`.\n",
    "\n",
    "\n",
    "### CUDA errors\n",
    "Sometimes you'll see this error:\n",
    "\n",
    "```\n",
    "RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #1 ‘mat1’\n",
    "```\n",
    "\n",
    "You'll notice the second type is `torch.cuda.FloatTensor`, this means it's a tensor that has been moved to the GPU. It's expecting a tensor with type `torch.FloatTensor`, no `.cuda` there, which means the tensor should be on the CPU. PyTorch can only perform operations on tensors that are on the same device, so either both CPU or both GPU. If you're trying to run your network on the GPU, check to make sure you've moved the model and all necessary tensors to the GPU with `.to(device)` where `device` is either `\"cuda\"` or `\"cpu\"`.\n",
    "\n",
    "\n",
    "[Tutorial: Deep Learning in PyTorch](http://iamtrask.github.io/2017/01/15/pytorch-tutorial/)\n",
    "\n",
    "[Notebooks](https://github.com/stephengineer/Machine-Learning/tree/main/Deep%20Learning/05%20Deep%20Learning%20with%20PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ae38a",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "### Normalizing image inputs\n",
    "Data normalization is an important pre-processing step. It ensures that each input (each pixel value, in this case) comes from a standard distribution. That is, the range of pixel values in one input image are the same as the range in another image. This standardization makes our model train and reach a minimum error, faster!\n",
    "\n",
    "\n",
    "### ReLU Activation Function\n",
    "The purpose of an activation function is to scale the outputs of a layer so that they are a consistent, small value. Much like normalizing input values, this step ensures that our model trains efficiently!\n",
    "\n",
    "A ReLU activation function stands for \"Rectified Linear Unit\" and is one of the most commonly used activation functions for hidden layers. It is an activation function, simply defined as the __positive__ part of the input, `x`. So, for an input image with any negative pixel values, this would turn all those values to `0`, black. You may hear this referred to as \"clipping\" the values to zero; meaning that is the lower bound.\n",
    "\n",
    "![ReLU](./img/relu-ex.png)\n",
    "\n",
    "\n",
    "### Cross-Entropy Loss\n",
    "In the [PyTorch documentation](https://pytorch.org/docs/stable/nn.html#crossentropyloss), you can see that the cross entropy loss function actually involves two steps:\n",
    "\n",
    "- It first applies a softmax function to any output is sees\n",
    "- Then applies [NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss); negative log likelihood loss\n",
    "\n",
    "Then it returns the average loss over a batch of data. Since it applies a softmax function, we do not have to specify that in the `forward` function of our model definition, but we could do this another way.\n",
    "\n",
    "#### Another approach\n",
    "We could separate the softmax and NLLLoss steps.\n",
    "\n",
    "- In the `forward` function of our model, we would explicitly apply a softmax activation function to the output, `x`.\n",
    "\n",
    "```py\n",
    "# a softmax layer to convert 10 outputs into a distribution of class probabilities\n",
    "x = F.log_softmax(x, dim=1)\n",
    "\n",
    "return x\n",
    "```\n",
    "\n",
    "- Then, when defining our loss criterion, we would apply NLLLoss\n",
    "\n",
    "```py\n",
    "# cross entropy loss combines softmax and nn.NLLLoss() in one single class\n",
    "# here, we've separated them\n",
    "criterion = nn.NLLLoss()\n",
    "```\n",
    "\n",
    "This separates the usual `criterion = nn.CrossEntropy()` into two steps: softmax and NLLLoss, and is a useful approach should you want the output of a model to be class probabilities rather than class scores.\n",
    "\n",
    "\n",
    "### Validation Set: Takeaways\n",
    "\n",
    "Measure how well a model generalizes, during training\n",
    "Tell us when to stop training a model; when the validation loss stops decreasing (and especially when the validation loss starts increasing and the training loss is still decreasing)\n",
    "\n",
    "![imageClassificationSteps](./img/imageClassificationSteps.png)\n",
    "\n",
    "### Filters\n",
    "To detect changes in intensity in an image, you’ll be using and creating specific image filters that look at groups of pixels and react to alternating patterns of dark/light pixels. These filters produce an output that shows edges of objects and differing textures.\n",
    "\n",
    "### Frequency in images\n",
    "We have an intuition of what frequency means when it comes to sound. High-frequency is a high pitched noise, like a bird chirp or violin. And low frequency sounds are low pitch, like a deep voice or a bass drum. For sound, frequency actually refers to how fast a sound wave is oscillating; oscillations are usually measured in cycles/s ([Hz](https://en.wikipedia.org/wiki/Hertz)), and high pitches and made by high-frequency waves. Examples of low and high-frequency sound waves are pictured below. On the y-axis is amplitude, which is a measure of sound pressure that corresponds to the perceived loudness of a sound, and on the x-axis is time.\n",
    "\n",
    "![frequency](./img/frequency.png)\n",
    "\n",
    "#### High and low frequency\n",
    "Similarly, frequency in images is a __rate of change__. But, what does it means for an image to change? Well, images change in space, and a high frequency image is one where the intensity changes a lot. And the level of brightness changes quickly from one pixel to the next. A low frequency image may be one that is relatively uniform in brightness or changes very slowly. This is easiest to see in an example.\n",
    "\n",
    "![frequencyImage](./img/frequencyImage.png)\n",
    "\n",
    "Most images have both high-frequency and low-frequency components. In the image above, on the scarf and striped shirt, we have a high-frequency image pattern; this part changes very rapidly from one brightness to another. Higher up in this same image, we see parts of the sky and background that change very gradually, which is considered a smooth, low-frequency pattern.\n",
    "\n",
    "__High-frequency components also correspond to the edges of objects in images__, which can help us classify those objects.\n",
    "\n",
    "#### Edge Handling\n",
    "Kernel convolution relies on centering a pixel and looking at it's surrounding neighbors. So, what do you do if there are no surrounding pixels like on an image corner or edge? Well, there are a number of ways to process the edges, which are listed below. It’s most common to use padding, cropping, or extension. In extension, the border pixels of an image are copied and extended far enough to result in a filtered image of the same size as the original image.\n",
    "\n",
    "__Extend__ The nearest border pixels are conceptually extended as far as necessary to provide values for the convolution. Corner pixels are extended in 90° wedges. Other edge pixels are extended in lines.\n",
    "\n",
    "__Padding__ The image is padded with a border of 0's, black pixels.\n",
    "\n",
    "__Crop__ Any pixel in the output image which would require values from beyond the edge is skipped. This method can result in the output image being slightly smaller, with the edges having been cropped.\n",
    "\n",
    "### Pooling layers\n",
    "Some architectures choose to use [average pooling](https://pytorch.org/docs/stable/nn.html#avgpool2d), which chooses to average pixel values in a given window size. So in a 2x2 window, this operation will see 4 pixel values, and return a single, average of those four values, as output!\n",
    "\n",
    "This kind of pooling is typically not used for image classification problems because maxpooling is better at noticing the most important details about edges and other features in an image, but you may see this used in applications for which smoothing an image is preferable.\n",
    "\n",
    "### Padding\n",
    "Padding is just adding a border of pixels around an image. In PyTorch, you specify the size of this border.\n",
    "\n",
    "Why do we need padding?\n",
    "\n",
    "When we create a convolutional layer, we move a square filter around an image, using a center-pixel as an anchor. So, this kernel cannot perfectly overlay the edges/corners of images. The nice feature of padding is that it will allow us to control the spatial size of the output volumes (most commonly as we’ll see soon we will use it to exactly preserve the spatial size of the input volume so the input and output width and height are the same).\n",
    "\n",
    "The most common methods of padding are padding an image with all 0-pixels (zero padding) or padding them with the nearest pixel value. You can read more about calculating the amount of padding, given a kernel_size, [here](https://cs231n.github.io/convolutional-networks/#conv).\n",
    "\n",
    "### Formula: Number of Parameters in a Convolutional Layer\n",
    "The number of parameters in a convolutional layer depends on the supplied values of `filters/out_channels`, `kernel_size`, and `input_shape`. Let's define a few variables:\n",
    "\n",
    "- `K` - the number of filters in the convolutional layer\n",
    "- `F` - the height and width of the convolutional filters\n",
    "- `D_in` - the depth of the previous layer\n",
    "Notice that `K` = `out_channels`, and `F` = `kernel_size`. Likewise, `D_in` is the last value in the `input_shape` tuple, typically 1 or 3 (RGB and grayscale, respectively).\n",
    "\n",
    "Since there are `F*F*D_in` weights per filter, and the convolutional layer is composed of `K` filters, the total number of weights in the convolutional layer is `K*F*F*D_in`. Since there is one bias term per filter, the convolutional layer has `K` biases. Thus, the __number of parameters__ in the convolutional layer is given by `K*F*F*D_in + K`.\n",
    "\n",
    "### Formula: Shape of a Convolutional Layer\n",
    "The shape of a convolutional layer depends on the supplied values of `kernel_size`, `input_shape`, `padding`, and `stride`. Let's define a few variables:\n",
    "\n",
    "- `K` - the number of filters in the convolutional layer\n",
    "- `F` - the height and width of the convolutional filters\n",
    "- `S` - the stride of the convolution\n",
    "- `P` - the padding\n",
    "- `W_in` - the width/height (square) of the previous layer\n",
    "Notice that `K = out_channels`, `F = kernel_size`, and `S = stride`. Likewise, `W_in` is the first and second value of the `input_shape` tuple.\n",
    "\n",
    "The __depth__ of the convolutional layer will always equal the number of filters `K`.\n",
    "\n",
    "The spatial dimensions of a convolutional layer can be calculated as: `(W_in−F+2P)/S+1`\n",
    "\n",
    "### Optional Resources\n",
    "- Check out the [AlexNet](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) paper!\n",
    "- Read more about [VGGNet](https://arxiv.org/pdf/1409.1556.pdf) here.\n",
    "- The [ResNet](https://arxiv.org/pdf/1512.03385v1.pdf) paper can be found here.\n",
    "- Here's the [Keras documentation](https://keras.io/api/applications/) for accessing some famous CNN architectures.\n",
    "- Read this [detailed treatment](http://neuralnetworksanddeeplearning.com/chap5.html) of the vanishing gradients problem.\n",
    "- Here's a [GitHub repository](https://github.com/jcjohnson/cnn-benchmarks) containing benchmarks for different CNN architectures.\n",
    "- Visit the [ImageNet Large Scale Visual Recognition Competition (ILSVRC)](https://image-net.org/challenges/LSVRC/) website.\n",
    "\n",
    "### External Resource\n",
    "[Deep learning eBook](https://www.deeplearningbook.org/) (2016) authored by Ian Goodfellow, Yoshua Bengio, and Aaron Courville; published by Cambridge: MIT Press\n",
    "\n",
    "\n",
    "## Transfer Learning\n",
    "Transfer learning involves taking a pre-trained neural network and adapting the neural network to a new, different data set.\n",
    "\n",
    "Depending on both:\n",
    "\n",
    "- The size of the new data set, and\n",
    "- The similarity of the new data set to the original data set\n",
    "\n",
    "The approach for using transfer learning will be different. There are four main cases:\n",
    "\n",
    "1. New data set is small, new data is similar to original training data.\n",
    "2. New data set is small, new data is different from original training data.\n",
    "3. New data set is large, new data is similar to original training data.\n",
    "4. New data set is large, new data is different from original training data.\n",
    "\n",
    "A large data set might have one million images. A small data could have two-thousand images. The dividing line between a large data set and small data set is somewhat subjective. Overfitting is a concern when using transfer learning with a small data set.\n",
    "\n",
    "Images of dogs and images of wolves would be considered similar; the images would share common characteristics. A data set of flower images would be different from a data set of dog images.\n",
    "\n",
    "Each of the four transfer learning cases has its own approach. In the following sections, we will look at each case one by one.\n",
    "\n",
    "\n",
    "## Weight Initialization\n",
    "It's key to include an element of uniqueness, or __randomness__! Better weights might be selected randomly from within a specified range. By adding variety and all unique weight values, we can ensure that backpropagation will have different activations to look at in the hidden layers, and it can respond to those differences.\n",
    "\n",
    "### Additional Material\n",
    "- [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "- [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/pdf/1502.01852v1.pdf)\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167v2.pdf)\n",
    "\n",
    "\n",
    "## Autoencoders\n",
    "\n",
    "\n",
    "## Style Transfer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1d03c",
   "metadata": {},
   "source": [
    "## Projects\n",
    "\n",
    "- [Sentiment Analysis](https://github.com/stephengineer/Machine-Learning/tree/main/Deep%20Learning/Projects/00%20Sentiment%20Analysis)\n",
    "- [ImageClassifier](https://github.com/stephengineer/Machine-Learning/tree/main/Deep%20Learning/Projects/01%20Image%20Classifier)\n",
    "- [Predicting Bike-Sharing Patterns](https://github.com/stephengineer/Machine-Learning/tree/main/Deep%20Learning/Projects/02%20Bike-Sharing%20Patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0eebeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
